<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Valentin Gabeur</title>
  
  <meta name="author" content="Valentin Gabeur">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/valentin_profile_pic.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Valentin Gabeur</name>
              </p>
              <p>I am a PhD student at <a href="https://www.inria.fr/en">Inria</a> (<a href="https://team.inria.fr/thoth/">Thoth team</a>) and <a href="https://ai.google/research/">Google AI Research</a>, working on machine learning for video understanding.
                I am advised by <a href="https://en.wikipedia.org/wiki/Cordelia_Schmid">Cordelia Schmid</a> and <a href="https://lear.inrialpes.fr/people/alahari/">Karteek Alahari</a>.
		    </p>
		    <p>
          I have a MS in Robotics from <a href="https://www.univ-tlse3.fr/">Toulouse University</a> and a MS in Engineering from <a href="https://en.icam.fr/">ICAM Lille</a>.
              </p>
              <p>
              
               
              </p>
              <p style="text-align:center">
                <a href="mailto:removethisifyouarehumanvalentin.gabeur@inria.fr">Email</a> &nbsp/&nbsp
                <a href="Valentin_Gabeur_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=MtUjp-cAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/gabeur/"> LinkedIn </a> &nbsp/&nbsp
		            <a href="https://twitter.com/vgabeur">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/gabeur"> GitHub </a>
    
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/valentin_profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/valentin_profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Research</heading>
        
            <p>
              My research focuses on building models that can extract cross-modal information from videos.
            </p>
          </td>
            </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        		        <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/MMCVR.png" alt="mmcvr" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2111.01300">
                    <papertitle>Masking Modalities for Cross-modal Video Retrieval</papertitle>
                  </a>
                  <br>
                  <b>Valentin Gabeur</b>, Arsha Nagrani, Chen Sun, Karteek Alahari, Cordelia Schmid
                  <br>
                  <em>WACV</em>, 2022 &nbsp 
                  <br>
                  <a href="https://arxiv.org/abs/2111.01300">arXiv</a>
                  <p></p>
                  <p>Pre-training strategy for learning multi-modal fusion from unlabelled videos.</p>
                </td>
              </tr>
		
		
		        <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/MMT.png" alt="mmt" width="160" height="120">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2007.10639">
                    <papertitle>Multi-modal Transformer for Video Retrieval</papertitle>
                  </a>
                  <br>
                  <b>Valentin Gabeur</b>, Chen Sun, Karteek Alahari, Cordelia Schmid
                  <br>
                  <em>ECCV</em>, 2020 <b>(Spotlight paper)</b> &nbsp 
                  <br>
                  <a href="https://arxiv.org/abs/2007.10639">arXiv</a> / <a href="https://github.com/gabeur/mmt">code, models, data</a>
                  <p></p>
                  <p>Cross-modal architecture to encode language captions and videos in a common embedding space.
                    Winner of the <a href="https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/challenge.html">CVPR 2020 Video Pentathlon Challenge</a> </p>
                </td>
              </tr>
		        <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/Moulding.png" alt="moulding" width="160" height="120">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/1908.00439">
                    <papertitle>Moulding Humans: Non-parametric 3D Human Shape Estimation from Single Images</papertitle>
                  </a>
                  <br>
                  <b>Valentin Gabeur</b>, Jean-Sebastien Franco, Xavier Martin, Cordelia Schmid, Gregory Rogez
                  <br>
                  <em>ICCV</em>, 2019 &nbsp 
                  <br>
                  <a href="https://arxiv.org/abs/1908.00439">arXiv</a>
                  <p></p>
                  <p>Efficient 3D shape representation through the combination of depth maps.</p>
                </td>
              </tr>
		




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <th style="padding:20px;width:25%;vertical-align:middle;text-align: center">
                      <img src="images/video-pent-logo.svg" alt="video-pent" width="100" height="80" class="center">
            </th>
           <td width="75%" valign="center">
            <strong> CVPR 2020 Video Pentathlon Challenge </strong> (video retrieval competition)
            </br>
            First place
            </br>
            <a href="https://arxiv.org/pdf/2008.00744.pdf">report</a> /
            <a href="https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/challenge.html">challenge</a> /
            <a href="https://www.youtube.com/watch?v=L2rff2mu1gE">recording</a> 	
            </br>										 
            </br>
    
            </td>
            </tr>

          <tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Credits to <a href="https://jonbarron.info/">Jon Barron</a> for the template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
